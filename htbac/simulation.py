import os
import re
from typing import List
from operator import mul
from collections import OrderedDict, Sized
from itertools import product, izip
from abc import ABCMeta, abstractmethod, abstractproperty

import radical.utils as ru

import numpy as np
from radical.entk import Pipeline, Stage, Task

from .engine import Engine
from .abpath import AbFolder, AbFile

logger = ru.Logger(__name__, level='INFO')


class Simulatable:
    """Abstract base class for objects that can be simulated

    They can be used in the `radical.entk` package as executables.
    """
    __metaclass__ = ABCMeta

    @abstractmethod
    def generate_pipeline(self):
        """Generate a pipeline that can be submitted for execution.

        Returns
        -------
        Pipeline

        """
        raise NotImplementedError

    @abstractproperty
    def shared_data(self):
        """List of all the data that is required to be copied over from 'local' to the execution platform
        for the simulations.

        Note that this is not the input for a specific task, that can be data generated by previous runs. This
        is usually a list of structure files like PDBs. They will be accessible by tasks inside `$SHARED`.

        Returns
        -------
        List[str]
            List of paths to files to be copied over.
        """
        raise NotImplementedError

    @abstractproperty
    def cpus(self):
        """Number of cpus required to fulfill the needs of the job(s).

        Returns
        -------
        int
            core count
        """
        return 0

    @abstractmethod
    def configure_engine_for_resource(self, resource):
        """Configure engine for a specific resource.

        The engine specifications of the simulation depend on the resource. Therefore to configure this
        the simulation has to know about the resource that it is running on.

        Parameters
        ----------
        resource: dict
            Resource description.

        """
        raise NotImplementedError


class Chainable:
    """Simulation object that can use output from one simulation as input for itself.

    """
    _path = "$Pipeline_{pipeline}_Stage_{stage}_Task_{task}"

    def __init__(self):
        self._input_sim = None

    def add_input_simulation(self, input_sim):
        self._input_sim = input_sim

    def input_data(self, extensions=None, **ensemble):
        if self._input_sim is None:
            return list()

        path = self._path.format(stage=self._input_sim.name, pipeline='protocol', task=ensemble['task_name'])
        return [os.path.join(path, self._input_sim.name + "-" + ensemble["task_name"]+s) for s in (extensions or ['.coor', '.xsc', '.vel'])]

    def generate_stage(self):
        raise NotImplementedError


class Simulation(Simulatable, Chainable, Sized, AbFolder):

    def __init__(self, name='simulation'):
        """

        Parameters
        ----------
        name: str, optional
            Name of the simulation. Examples include "minimize", "equilibrate", etc. All <output>
            field in configuration files will use this value if you don't have ensembles!
        """

        self.name = name
        self.engine = None
        self.system = None

        self._processes = 1
        self._threads_per_process = 1
        self._variables = dict()
        self._ensembles = OrderedDict()

        AbFolder.__init__(self)
        Chainable.__init__(self)

    # Internal constants

    _sed = "sed -i.bak 's/<{}>/{}/g' {}"
    _placeholder = re.compile("<(\S+)>")

    def __repr__(self):
        return self.name

    def __getattr__(self, item):
        return getattr(self.system, item)

    # `Sized` protocol

    def __len__(self):
        return reduce(mul, (len(v) for v in self._ensembles.itervalues()), 1)

    # Public methods

    def add_variable(self, name, in_file=None, value=None):
        logger.debug('Adding variable called {}.'.format(name))
        if not hasattr(self, name) or (getattr(self, name) is None and value is not None):
            logger.debug('Setting the value to {}.'.format(value))
            if callable(value):
                logger.debug('Value is stored as property because it is callable')
                setattr(self.__class__, name, property(value))
            else:
                setattr(self, name, value)

        if in_file in self._variables:
            self._variables[in_file].add(name)
        elif in_file is not None:
            self._variables[in_file] = {name}

    def all_variables_defined(self):
        return all(self.get_variable(v) is not None for vs in self._variables.values() for v in vs)

    def get_variables(self):
        return {f: [(v, self.get_variable(v)) for v in vs] for f, vs in self._variables.items()}

    def get_variable(self, var):
        v = None
        try:
            v = getattr(self, var)
            if v is None:
                logger.debug('Attempting to get variable from system instance.')
                v = getattr(self.system, var)
        except AttributeError:
            logger.warn('Variable `{}` is not defined! Returning None.'.format(var))
            v = None
        finally:
            return v

    def add_ensemble(self, name, values):
        """Add a parameter to the simulation that you want multiple values to be run with.
        For example running multiple systems with the same configuration, or trying out a
        range of cutoff distances to see which one works best. This is very powerful!

        Parameters
        ----------
        name: str
            The name of the attribute that will become an ensemble. Has to be alphanumeric only!
        values: list or np.ndarray
            List of values that the attribute can have.

        """

        if not name.isalnum():
            raise ValueError('Ensemble name must be alpha numeric only!')

        if not hasattr(self, name):
            self.add_variable(name)

        logger.info('Adding ensemble {} with possible values {}.'.format(name, values))
        self._ensembles[name] = values

    def add_input_simulation(self, input_sim):
        """

        Parameters
        ----------
        input_sim: Simulation

        """
        self._input_sim = input_sim

    def add_input_file(self, input_file, is_executable_argument, auto_detect_variables=True):
        """

        Parameters
        ----------
        input_file: str
        is_executable_argument: bool
        auto_detect_variables: bool
            Automatically detect placeholders in the file (of the form <placeholder>) and add
            them as variables to the object. Default is True.
        """

        abfile = AbFile(path=input_file, is_executable_argument=is_executable_argument)
        self._files.append(abfile)

        if auto_detect_variables:
            with open(input_file) as f:
                variables = set(re.findall(self._placeholder, f.read()))
                abfile.needs_copying = bool(variables)
                for var in variables:
                    self.add_variable(var, in_file=abfile.name)

    # Methods used by underlying execution framework

    def generate_task(self, **ensembles):
        """ Generate a `radical.entk` task.

        Parameters
        ----------
        ensembles: dict, OrderedDict
            Dictionary of the *current* values of variables that are ensembles. All the variables
            that were declared with `add_ensemble` should be specified here so that a correct
            task object can be generated.
        """

        [setattr(self, k, w) for k, w in ensembles.iteritems()]

        if not self.all_variables_defined():
            raise ValueError('Some variables are not defined!')

        task = Task()
        task.name = ensembles['task_name']

        task.pre_exec += self.engine.pre_exec
        task.executable += self.engine.executable
        task.arguments += self.engine.arguments
        task.cpu_reqs = {'processes': self._processes,
                         'process_type': 'MPI' if self.engine.uses_mpi else None,
                         'threads_per_process': self._threads_per_process,
                         'thread_type': None
                         }

        task.arguments.extend(self.arguments)
        task.copy_input_data.extend(self.copied_files)
        task.copy_input_data.extend(self.system.copied_files)

        task.post_exec.append('echo "{}" > sim_desc.txt'.format(task.name))

        task.link_input_data.extend(self.input_data(**ensembles))
        task.link_input_data.extend(self.system.linked_files)

        task.pre_exec.extend(self._sed.format(n, v, f) for f, vs in self.get_variables().items() for n, v in vs)

        return task

    def generate_stage(self):
        s = Stage()
        s.name = self.name
        s.add_tasks({self.generate_task(**x) for x in self._ensemble_product()})

        return s

    def generate_pipeline(self):
        p = Pipeline()
        p.name = 'protocol'
        p.add_stages(self.generate_stage())

        return p

    # `Simulatable` protocol implementation

    @property
    def shared_data(self):
        """
        List of all the files that need to be staged to remote.
        """

        # If `system` is an ensemble than return that otherwise return
        # just the one system.
        systems = self._ensembles.get('system', [self.system])

        return self.shared_files + [d for s in systems for d in s.shared_files]

    @property
    def cpus(self):
        return self._processes * self._threads_per_process * len(self)

    @property
    def processes(self):
        return self._processes

    @processes.setter
    def processes(self, value):
        if isinstance(self.engine, Engine) and self.engine.cpus:
            raise ValueError('Engine has REQUIRED core count. Do not set simulation cpus!')
        self._processes = value

    @property
    def threads_per_process(self):
        return self._threads_per_process

    @threads_per_process.setter
    def threads_per_process(self, value):
        self._threads_per_process = value

    def configure_engine_for_resource(self, resource):
        if not isinstance(self.engine, str):
            raise ValueError('Engine type not set!')

        engine = resource[self.engine]

        if isinstance(engine, str):
            engine = resource[engine]

        self.engine = Engine.from_dictionary(**engine)

        logger.info("Engine is using executable: {}".format(self.engine.executable))

        if self.engine.cpus:
            if self.cpus:
                raise ValueError('Engine has REQUIRED core count. Do not set simulation cpus!')

            logger.debug("Setting simulation core count to the REQUIRED value by engine ({}). "
                         "Do not alter this!".format(self.engine.cpus))
            self._processes = self.engine.cpus

    # Private methods

    def _ensemble_product(self):
        ensembles = [OrderedDict(izip(self._ensembles, x)) for x in product(*self._ensembles.itervalues())]
        for ensemble in ensembles:
            # TODO: should we sort the values of ensemble (alphabetically) so ids can match up between stages?
            task_name = "-".join("{}-{}".format(k, w) for k, w, in ensemble.items()) or "task"
            output = self.name + "-" + task_name
            input_name = None if self._input_sim is None else self._input_sim.name + "-" + task_name

            ensemble["task_name"] = task_name
            ensemble["output"] = output
            ensemble["input"] = input_name

        return ensembles


