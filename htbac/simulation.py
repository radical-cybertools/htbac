import os
import re
from typing import List
from operator import mul
from collections import OrderedDict, Sized
from itertools import product, izip
from abc import ABCMeta, abstractmethod, abstractproperty

import radical.utils as ru

import numpy as np
from radical.entk import Pipeline, Stage, Task

from .engine import Engine
from .abpath import AbFolder, AbFile

logger = ru.Logger(__name__, level='INFO')


class Simulatable:
    """Abstract base class for objects that can be simulated

    They can be used in the `radical.entk` package as executables.
    """
    __metaclass__ = ABCMeta

    @abstractmethod
    def generate_pipeline(self):
        """Generate a pipeline that can be submitted for execution.

        Returns
        -------
        Pipeline

        """
        raise NotImplementedError

    @abstractproperty
    def shared_data(self):
        """List of all the data that is required to be copied over from 'local' to the execution platform
        for the simulations.

        Note that this is not the input for a specific task, that can be data generated by previous runs. This
        is usually a list of structure files like PDBs. They will be accessible by tasks inside `$SHARED`.

        Returns
        -------
        List[str]
            List of paths to files to be copied over.
        """
        raise NotImplementedError

    @abstractproperty
    def cpus(self):
        """Number of cpus required to fulfill the needs of the job(s).

        Returns
        -------
        int
            core count
        """
        return 0

    @abstractmethod
    def configure_engine_for_resource(self, resource):
        """Configure engine for a specific resource.

        The engine specifications of the simulation depend on the resource. Therefore to configure this
        the simulation has to know about the resource that it is running on.

        Parameters
        ----------
        resource: dict
            Resource description.

        """
        raise NotImplementedError


class Chainable:
    """Simulation object that can use output from one simulation as input for itself.

    There is a way to also copy the settings of the previous simulations over.

    """
    __metaclass__ = ABCMeta

    @abstractmethod
    def add_input_simulation(self, input_sim, clone_settings):
        raise NotImplementedError

    @abstractmethod
    def generate_stage(self):
        raise NotImplementedError


class Simulation(Simulatable, Chainable, Sized, AbFolder):

    def __init__(self, name='simulation'):
        """

        Parameters
        ----------
        name: str, optional
            Name of the simulation. Examples include "minimize", "equilibrate", etc. All <output>
            field in configuration files will use this value!
        """

        self.name = name
        self.engine = None
        self.system = None

        self._input_sim = None  # Input simulation. Needs to link data generated here.
        # self._input_files = list()  # Files than are input to this simulation
        # self._arguments = list()  # Files that are arguments to the executable.

        self._processes = 1
        self._threads_per_process = 1
        self._variables = dict()
        self._ensembles = OrderedDict()

        AbFolder.__init__(self)

    # Internal constants

    _path = "$Pipeline_{pipeline}_Stage_{stage}_Task_{task}"
    _sed = "sed -i.bak 's/<{}>/{}/g' {}"
    _placeholder = re.compile("<(\S+)>")

    def __repr__(self):
        return self.name

    def output_data(self, for_ensemble):
        task = "-".join("{}-{}".format(k, w) for k, w, in for_ensemble.iteritems()) or "sim"
        path = self._path.format(stage=self.name, pipeline='protocol', task=task)
        return [os.path.join(path, self.name+s) for s in ['.coor', '.xsc', '.vel']]

    @property
    def input(self):
        return self._input_sim.name if self._input_sim else str()

    @property
    def output(self):
        return self.name

    def __getattr__(self, item):
        return getattr(self.system, item)

    # `Sized` protocol

    def __len__(self):
        return reduce(mul, (len(v) for v in self._ensembles.itervalues()), 1)

    # Public methods

    def add_variable(self, name, in_file=None, value=None):
        logger.debug('Adding variable called {}.'.format(name))
        if not hasattr(self, name) or getattr(self, name) is None:
            logger.debug('Setting the value to {}.'.format(value))
            if callable(value):
                logger.debug('Value is stored as property because it is callable')
                setattr(self.__class__, name, property(value))
            else:
                setattr(self, name, value)

        if in_file in self._variables:
            self._variables[in_file].add(name)
        elif in_file is not None:
            self._variables[in_file] = {name}

    def all_variables_defined(self):
        return all(self.get_variable(v) is not None for vs in self._variables.values() for v in vs)

    def get_variables(self):
        return {f: [(v, self.get_variable(v)) for v in vs] for f, vs in self._variables.items()}

    def get_variable(self, var):
        v = getattr(self, var)

        if v is not None:
            return v

        logger.debug('Getting variable from system.')
        return getattr(self.system, var)

    def add_ensemble(self, name, values):
        """Add a parameter to the simulation that you want multiple values to be run with.
        For example running multiple systems with the same configuration, or trying out a
        range of cutoff distances to see which one works best. This is very powerful!

        Parameters
        ----------
        name: str
            The name of the attribute that will become an ensemble. Has to be alphanumeric only!
        values: list or np.ndarray
            List of values that the attribute can have.

        """

        if not name.isalnum():
            raise ValueError('Ensemble name must be alpha numeric only!')

        if not hasattr(self, name):
            self.add_variable(name)

        logger.info('Adding ensemble {} with possible values {}.'.format(name, values))
        self._ensembles[name] = values

    def add_input_simulation(self, input_sim, clone_settings):
        """

        Parameters
        ----------
        input_sim: Simulation
        clone_settings: bool

        """
        self._input_sim = input_sim

        if clone_settings:
            self.engine = input_sim.engine
            self.processes = input_sim._processes
            self.threads_per_process = input_sim._threads_per_process
            self.system = input_sim.system

            for in_file, attrs in input_sim._variables.iteritems():
                for attr in attrs:
                    self.add_variable(attr, value=getattr(input_sim, attr))

            for ens, values in input_sim._ensembles.iteritems():
                self.add_ensemble(ens, values)

    def add_input_file(self, input_file, is_executable_argument, auto_detect_variables=True):
        """

        Parameters
        ----------
        input_file: str
        is_executable_argument: bool
        auto_detect_variables: bool
            Automatically detect placeholders in the file (of the form <placeholder>) and add
            them as variables to the object. Default is True.
        """

        abfile = AbFile(path=input_file, is_executable_argument=is_executable_argument)
        self._files.append(abfile)

        if auto_detect_variables:
            with open(input_file) as f:
                variables = set(re.findall(self._placeholder, f.read()))
                abfile.needs_copying = bool(variables)
                for var in variables:
                    self.add_variable(var, in_file=abfile.name)

    # Methods used by underlying execution framework

    def generate_task(self, **ensembles):
        """ Generate a `radical.entk` task.

        Parameters
        ----------
        ensembles: dict
            Dictionary of the *current* values of variables that are ensembles. All the variables
            that were declared with `add_ensemble` should be specified here so that a correct
            task object can be generated.
        """

        [setattr(self, k, w) for k, w in ensembles.iteritems()]

        if not self.all_variables_defined():
            raise ValueError('Some variables are not defined!')

        task = Task()
        task.name = "-".join("{}-{}".format(k, w) for k, w, in ensembles.iteritems()) or "sim"
        
        task.pre_exec += self.engine.pre_exec
        task.executable += self.engine.executable
        task.arguments += self.engine.arguments
        task.cpu_reqs = {'processes': self._processes,
                         'process_type': 'MPI' if self.engine.uses_mpi else None,
                         'threads_per_process': self._threads_per_process,
                         'thread_type': None
                         }
                         
        task.arguments.extend(self.arguments)
        task.copy_input_data.extend(self.copied_files)
        task.copy_input_data.extend(self.system.copied_files)
        
        task.post_exec.append('echo "{}" > sim_desc.txt'.format(task.name))

        if self._input_sim:
            task.link_input_data.extend(self._input_sim.output_data(for_ensemble=ensembles))

        task.link_input_data.extend(self.system.linked_files)

        task.pre_exec.extend(self._sed.format(n, v, f) for f, vs in self.get_variables().items() for n, v in vs)
        task.lfs = [len(v) for v in self._ensembles.values()][0]
        task.tag = task.name 
        
        return task

    def generate_stage(self):
        s = Stage()
        s.name = self.name
        s.add_tasks({self.generate_task(**x) for x in self._ensemble_product()})

        return s

    def generate_pipeline(self):
        p = Pipeline()
        p.name = 'protocol'
        p.add_stages(self.generate_stage())

        return p

    # `Simulatable` protocol implementation

    @property
    def shared_data(self):
        """
        List of all the files that need to be staged to remote.
        """

        # If `system` is an ensemble than return that otherwise return
        # just the one system.
        systems = self._ensembles.get('system', [self.system])

        return self.shared_files + [d for s in systems for d in s.shared_files]

    @property
    def cpus(self):
        return self._processes * self._threads_per_process * len(self)

    @property
    def processes(self):
        return self._processes

    @processes.setter
    def processes(self, value):
        if isinstance(self.engine, Engine) and self.engine.cpus:
            raise ValueError('Engine has REQUIRED core count. Do not set simulation cpus!')
        self._processes = value

    @property
    def threads_per_process(self):
        return self._threads_per_process

    @threads_per_process.setter
    def threads_per_process(self, value):
        self._threads_per_process = value

    def configure_engine_for_resource(self, resource):
        if not isinstance(self.engine, str):
            raise ValueError('Engine type not set!')

        engine = resource[self.engine]

        if isinstance(engine, str):
            engine = resource[engine]

        self.engine = Engine.from_dictionary(**engine)

        logger.info("Engine is using executable: {}".format(self.engine.executable))

        if self.engine.processes and self.engine.threads_per_process:
            if self.processes or self.threads_per_process:
                raise ValueError('Engine has REQUIRED core count. Do not set simulation cpus!')

            logger.debug("Setting simulation core count to the REQUIRED value by engine ({}). "
                         "Do not alter this!".format(self.engine.processes))
            self._processes = self.engine.processes 
            self._threads_per_process = self.engine.threads_per_process


    # Private methods

    def _ensemble_product(self):
        return (dict(izip(self._ensembles, x)) for x in product(*self._ensembles.itervalues()))
